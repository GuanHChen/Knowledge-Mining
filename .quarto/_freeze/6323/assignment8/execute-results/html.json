{
  "hash": "307e08924c774d38f96463bc03a0f5fb",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Knowledge Mining (EPPS 6323)\"\nsubtitle: \"Assignment 8\"\nauthor: \"Guan Chen\"\ndate: last-modified\ntoc: false\ntitle-block-banner: true\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nrequire(ISLR)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: ISLR\n```\n\n\n:::\n\n```{.r .cell-code}\nrequire(MASS)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: MASS\n```\n\n\n:::\n\n```{.r .cell-code}\nrequire(descr)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: descr\n```\n\n\n:::\n\n```{.r .cell-code}\nattach(Smarket)\n\n## Linear Discriminant Analysis\nfreq(Direction)\n```\n\n::: {.cell-output-display}\n![](assignment8_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDirection \n      Frequency Percent\nDown        602   48.16\nUp          648   51.84\nTotal      1250  100.00\n```\n\n\n:::\n\n```{.r .cell-code}\ntrain = Year<2005\nlda.fit=lda(Direction~Lag1+Lag2,data=Smarket, subset=Year<2005)\nlda.fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCall:\nlda(Direction ~ Lag1 + Lag2, data = Smarket, subset = Year < \n    2005)\n\nPrior probabilities of groups:\n    Down       Up \n0.491984 0.508016 \n\nGroup means:\n            Lag1        Lag2\nDown  0.04279022  0.03389409\nUp   -0.03954635 -0.03132544\n\nCoefficients of linear discriminants:\n            LD1\nLag1 -0.6420190\nLag2 -0.5135293\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(lda.fit, col=\"dodgerblue\")\n```\n\n::: {.cell-output-display}\n![](assignment8_files/figure-html/unnamed-chunk-1-2.png){width=672}\n:::\n\n```{.r .cell-code}\nSmarket.2005=subset(Smarket,Year==2005) # Creating subset with 2005 data for prediction\nlda.pred=predict(lda.fit,Smarket.2005)\nnames(lda.pred)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"class\"     \"posterior\" \"x\"        \n```\n\n\n:::\n\n```{.r .cell-code}\nlda.class=lda.pred$class\nDirection.2005=Smarket$Direction[!train] \ntable(lda.class,Direction.2005) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         Direction.2005\nlda.class Down  Up\n     Down   35  35\n     Up     76 106\n```\n\n\n:::\n\n```{.r .cell-code}\ndata.frame(lda.pred)[1:5,]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     class posterior.Down posterior.Up         LD1\n999     Up      0.4901792    0.5098208  0.08293096\n1000    Up      0.4792185    0.5207815  0.59114102\n1001    Up      0.4668185    0.5331815  1.16723063\n1002    Up      0.4740011    0.5259989  0.83335022\n1003    Up      0.4927877    0.5072123 -0.03792892\n```\n\n\n:::\n\n```{.r .cell-code}\ntable(lda.pred$class,Smarket.2005$Direction)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      \n       Down  Up\n  Down   35  35\n  Up     76 106\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(lda.pred$class==Smarket.2005$Direction)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.5595238\n```\n\n\n:::\n:::\n\n\nThe best subset selection model will have the smallest training rss.\nThe stepwise selection models will have the smallest test rss. Between the forward and backward models, it will depend on the specific data being modeled. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nx <- rnorm(100)\neps <- rnorm(100)\n\ny <- 4 + 9 * x + 2 * x^2 + x^3 + eps\n\nplot(x)\n```\n\n::: {.cell-output-display}\n![](assignment8_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(y)\n```\n\n::: {.cell-output-display}\n![](assignment8_files/figure-html/unnamed-chunk-2-2.png){width=672}\n:::\n\n```{.r .cell-code}\nrequire(leaps)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: leaps\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'leaps' was built under R version 4.3.3\n```\n\n\n:::\n\n```{.r .cell-code}\nbest_subset <- regsubsets(y ~ poly(x, 10, raw = T), data = data.frame(y,x, nvmax = 10))\nbic <- summary(best_subset)$bic\ncp <- summary(best_subset)$cp\nadjr2 <- summary(best_subset)$adjr2\n\nplot(bic, type = \"b\", pch = 16, col = \"blue\", \n     xlab = \"Model Number\", ylab = \"BIC Value\", \n     main = \"BIC Values for Different Models\")\n```\n\n::: {.cell-output-display}\n![](assignment8_files/figure-html/unnamed-chunk-2-3.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(cp, type = \"b\", pch = 16, col = \"blue\", \n     xlab = \"Model Number\", ylab = \"Cp Value\", \n     main = \"Cp Values for Different Models\")\n```\n\n::: {.cell-output-display}\n![](assignment8_files/figure-html/unnamed-chunk-2-4.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(adjr2, type = \"b\", pch = 16, col = \"blue\", \n     xlab = \"Model Number\", ylab = \"Adjusted R^2 Value\", \n     main = \"Adjusted R^2 Values for Different Models\")\n```\n\n::: {.cell-output-display}\n![](assignment8_files/figure-html/unnamed-chunk-2-5.png){width=672}\n:::\n\n```{.r .cell-code}\nwhich.min(bic)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3\n```\n\n\n:::\n\n```{.r .cell-code}\nwhich.min(cp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3\n```\n\n\n:::\n\n```{.r .cell-code}\nwhich.max(adjr2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 7\n```\n\n\n:::\n\n```{.r .cell-code}\ncoef(best_subset, id = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          (Intercept) poly(x, 10, raw = T)1 poly(x, 10, raw = T)2 \n             3.970394              8.920446              1.908457 \npoly(x, 10, raw = T)3 \n             1.020436 \n```\n\n\n:::\n:::\n\nThe best model is model 3 which has the lowest BIC value and Cp value. While model 7 has the maximum adjusted R squared value, the R squared plot begins to plateau at model 3, and I suspect overfitting to occur. \n\nThe coefficients for model 3 are 3.97, 8.92, 1.91, and 1.02 for the intercept, B1, B2, and B3 respectively.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfor_subset <- regsubsets(y ~ poly(x, 10, raw = T), data = data.frame(y,x, nvmax = 10), method = \"forward\")\n\nplot(summary(for_subset)$bic, type = \"b\", pch = 16, col = \"blue\", \n     xlab = \"Model Number\", ylab = \"BIC Value\", \n     main = \"BIC Values for Different Models\")\n```\n\n::: {.cell-output-display}\n![](assignment8_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(summary(for_subset)$cp, type = \"b\", pch = 16, col = \"blue\", \n     xlab = \"Model Number\", ylab = \"Cp Value\", \n     main = \"Cp Values for Different Models\")\n```\n\n::: {.cell-output-display}\n![](assignment8_files/figure-html/unnamed-chunk-3-2.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(summary(for_subset)$adjr2, type = \"b\", pch = 16, col = \"blue\", \n     xlab = \"Model Number\", ylab = \"Adjusted R^2 Value\", \n     main = \"Adjusted R^2 Values for Different Models\")\n```\n\n::: {.cell-output-display}\n![](assignment8_files/figure-html/unnamed-chunk-3-3.png){width=672}\n:::\n\n```{.r .cell-code}\nwhich.min(summary(for_subset)$bic)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3\n```\n\n\n:::\n\n```{.r .cell-code}\nwhich.min(summary(for_subset)$cp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3\n```\n\n\n:::\n\n```{.r .cell-code}\nwhich.max(summary(for_subset)$adjr2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4\n```\n\n\n:::\n\n```{.r .cell-code}\ncoef(for_subset, id = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          (Intercept) poly(x, 10, raw = T)1 poly(x, 10, raw = T)2 \n             3.970394              8.920446              1.908457 \npoly(x, 10, raw = T)3 \n             1.020436 \n```\n\n\n:::\n:::\n\n\nThe best model is model 3 again with the lowest BIC and Cp values. Model 4 wins the best adjusted R squared value but model 3 has a similar adjusted R squared value according to the plot. \n\nThe coefficients for model 3 are 3.97, 8.92, 1.91, and 1.02 for the intercept, B1, B2, and B3 respectively. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbac_subset <- regsubsets(y ~ poly(x, 10, raw = T), data = data.frame(y,x, nvmax = 10), method = \"backward\")\n\nplot(summary(bac_subset)$bic, type = \"b\", pch = 16, col = \"blue\", \n     xlab = \"Model Number\", ylab = \"BIC Value\", \n     main = \"BIC Values for Different Models\")\n```\n\n::: {.cell-output-display}\n![](assignment8_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(summary(bac_subset)$cp, type = \"b\", pch = 16, col = \"blue\", \n     xlab = \"Model Number\", ylab = \"Cp Value\", \n     main = \"Cp Values for Different Models\")\n```\n\n::: {.cell-output-display}\n![](assignment8_files/figure-html/unnamed-chunk-4-2.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(summary(bac_subset)$adjr2, type = \"b\", pch = 16, col = \"blue\", \n     xlab = \"Model Number\", ylab = \"Adjusted R^2 Value\", \n     main = \"Adjusted R^2 Values for Different Models\")\n```\n\n::: {.cell-output-display}\n![](assignment8_files/figure-html/unnamed-chunk-4-3.png){width=672}\n:::\n\n```{.r .cell-code}\nwhich.min(summary(bac_subset)$bic)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4\n```\n\n\n:::\n\n```{.r .cell-code}\nwhich.min(summary(bac_subset)$cp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4\n```\n\n\n:::\n\n```{.r .cell-code}\nwhich.max(summary(bac_subset)$adjr2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4\n```\n\n\n:::\n\n```{.r .cell-code}\ncoef(bac_subset, id = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          (Intercept) poly(x, 10, raw = T)1 poly(x, 10, raw = T)2 \n            3.9620068             9.8934015             1.9689642 \npoly(x, 10, raw = T)5 \n            0.1748705 \n```\n\n\n:::\n:::\n\n\nUsing the backwards stepwise selection method, model 4 performs the best on all 3 metrics. The coefficients are 3.96, 9.89, 1.97, and 0.17 for the intercept, B1, B2, and B3 respectively. \n\n",
    "supporting": [
      "assignment8_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}